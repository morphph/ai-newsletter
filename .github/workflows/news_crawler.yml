name: News Crawler V3
on:
  workflow_dispatch:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'

jobs:
  crawl-news:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
      
      - name: Run News Crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
          TWITTER_API_KEY: ${{ secrets.TWITTER_API_KEY || 'dummy_key_for_testing' }}
        run: |
          cd backend
          python src/workers/news_crawler_v3.py --once